# -*- coding: utf-8 -*-
"""q2_lastHWbioimage.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1T8DXemeJmOekhDuQOWWygJyH5iCTvi0S
"""

import cv2

import cv2
import numpy as np
from PIL import Image
import matplotlib.pyplot as plt
 
# Open the image files.
inputImage = cv2.imread("input_fig.jpg")  # Image to be aligned.
# print(img1_color.shape)
refImage = cv2.imread("ref.jpg")    # Reference image.

# print("Input Image")
# print(plt.imshow(inputImage))

# Convert to grayscale.
#Code reference: https://www.geeksforgeeks.org/image-registration-using-opencv-python/
img1 = cv2.cvtColor(inputImage, cv2.COLOR_BGR2GRAY)
img2 = cv2.cvtColor(refImage, cv2.COLOR_BGR2GRAY)
height, width = img2.shape
 
# Create ORB detector with 5000 features.
orb_detector = cv2.ORB_create(5000)
 
# Find keypoints and descriptors.
kp1, d1 = orb_detector.detectAndCompute(img1, None)
kp2, d2 = orb_detector.detectAndCompute(img2, None)
 
# Match features between the two images.
# Brute Force matcher with Hamming distance as measurement mode.
matcher = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck = True)
 
# Match the two sets of descriptors.
matches = matcher.match(d1, d2)
matches = list(matches)

# Sort matches on the basis of their Hamming distance.
matches.sort(key = lambda x: x.distance)
 
# Take the top 90 % matches forward.
matches = matches[:int(len(matches)*0.9)]
no_of_matches = len(matches)
 
# Define empty matrices of shape no_of_matches * 2.
p1 = np.zeros((no_of_matches, 2))
p2 = np.zeros((no_of_matches, 2))
 
for i in range(len(matches)):
  p1[i, :] = kp1[matches[i].queryIdx].pt
  p2[i, :] = kp2[matches[i].trainIdx].pt
 
# Find the homography matrix.
homography, mask = cv2.findHomography(p1, p2, cv2.RANSAC)
 
# Use this matrix to transform the
# colored image wrt the reference image.
transformImage = cv2.warpPerspective(inputImage,
                    homography, (width, height))
plt.imshow(transformImage)
# cv2.imwrite('output.jpg', transformed_img)